## webui(automatic1111)のbatch img2imgのための時間軸的因果付与フィルター

## 例

i2i出力そのまま（フィルターなし）→i2i出力をフィルターにかけたもの


https://user-images.githubusercontent.com/59357372/229110539-7d995541-950a-4b70-9d39-9b5a0b39d4a8.mov


## 説明
https://github.com/AUTOMATIC1111/stable-diffusion-webui

stable-diffusion-webuiのbatchimg2imgは各画像の因果性を考慮せず、個々に独立に画像を生成する。

一方で、連続した画像、動画ファイルの連番切り出し画像などをbatchimg2imgで処理し、AIにレタッチさせたい、という需要は少なからずある。
しかし、そうした連続性のある、時間軸に沿ったシーケンシャルな画像に対しても、batchimg2imgは各画像の前後関係、シーケンシャルな時間関係を考慮せず、バラバラに画像を出力し、結果として「ちらつき」に満ちた、まとまりのない、ギクシャクした画像群を生成する。

このリポジトリではそうした、短時間における一貫性のなさを解消するための、時間軸を考慮した因果性を与えるフィルターを提供する。

## 使い方
requirements.txtに沿って各種ライブラリをインストールする。

pip install -r requirements.txt

filter4batchi2i.pyを実行する。

python filter4batchi2i.py

## パラメータ
- --inputdir　入力ディレクトリ。ここにbatchi2iの出力結果の画像ファイル群を置く。
- --outputdir　出力ディレクトリ。ここに連番画像フィルター処理のファイルが出力される。
- --reverb_depth 良い意味で「ブレ」をかける深さ。かけすぎると「良い意味」ではなくなっていく。
- --scale　rifeに渡す処理の解像度パラメータ。0.5, 1.0, 2.0, 4.0 の値のみ取る（らしいが）。値が小さいほど、処理速度は上がるが「ボケ」が出る。
- --rife rifeライブラリを使い、フレームシーケンスにフィルターを適用する。
- --realesrgan realesrganライブラリを使い、フィルターによって生じる「ブレ」を軽減する。


## 原理
基本的にはi2iの出力結果を連続した画像とみなし、LPF(ローパスフィルター)をかけ、リバーブ（モーションブラー）をかけ、そうして画像間の時間軸的因果関係を仮定して、ぼやかすように混合する。
混合するだけでは「ボケ」、「ブレ」が出るだけなので、--reverb_depthの値を調整し、--realesrganで「ブレ」を軽減し、そうして混合の具合を調節する。

## 備考（良い処理結果を出すために）
このフィルターでは、画像間の演算に一般的なピクセルブレンドではなく、AI的な補間を用いている。
しかし、そういう風に処理してさえも、元の（i2i前の）画像がとびとびだと、i2iの出力、そしてこのフィルターの出力はとびとび、ブレブレになってしまう。

処理速度向上のためにi2i前にフレームを間引き、i2i後にフレーム補間をかけるのが常套手段ではあるが、
このフィルターで良い結果を得るためには、むしろi2i前にフレーム補間をしてサンプリングレートを増やし、LPF(ローパスフィルター)が効果的にかかるようにした方が良いだろう。
もちろんi2iの処理時間は増える。このフィルター上でも、さらに処理時間は増える。質と処理速度のトレードオフである。

また、そうしてさえも飛び・一貫性のなさ・フィルターによるブレ・ボケが出る場合は多分にある。そうした場合は映像編集ソフト（DavinciResolveのような）を使い、フリッカー除去、時間軸的ノイズ除去、シャープ化など後処理をするといいだろう。

## 更新履歴
・2023/03/31：リポジトリの一新（別リポジトリにすべきだったか？）。
・2023/03/25：シーケンス画像の変化量に応じて「混合」のパラメータを動的に変更するようにした。
